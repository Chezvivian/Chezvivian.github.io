---
title: '2024-11-29 GLOC_24 实验记录'
comments: true
tags:
  - thoughts
--- 


GLOC_24 游戏翻译眼动实验目前正在进行时，趁体验和记忆最新鲜的时候来记录一下实验前期和过程中的一些经验和感想，以给未来的实验提供一些基准，也供同事或者感兴趣的同学们进行参考。


* TOC  
{:toc}  

## 实验设计

### 一、文本筛选、测试（基础和关键）

自变量的选取和文本筛选是翻译认知过程实验的一个最基础、最核心的问题，很大程度上决定了研究的价值和最终数据是否能呈现显著差异。这是重中之重，也是从实验伊始占据我最多时间的问题。今年4月份我开始准备做实验，到7月份确定基本的设计框架，通过了学院的伦理审查，也申请到了眼动实验室的使用权限。但是暑假期间，却一直卡在文本筛选这一关，一方面是全职带娃，没有任何时间可以肉身到学校；另一方面主要是研究兴趣有一点转变，在之前文章里[2024-11-03 一年总结](https://chezvivian.github.io//one-year-summary/)里也提到。所以，在经过一些调整和思考之后，GLOC_24的实验代码正式在9月30日敲定。之后的文本筛选、测试很快在一个月内就完成了（10月25日）。

文本筛选工作也是最痛苦的 dirty work. 这次游戏翻译实验，先选定游戏文本作为大的范畴，然后根据不同游戏平台、类型、文本多样性筛选出最感兴趣、最适合的单个游戏主体。下一步获取游戏全部的文本、视频 walkthrough 资料，这里包括 Game wiki 上的资料搜集、Youtube上的视频抓取，还有游戏脚本的梳理。再从这款游戏的各类文本类型中挑选出有代表性的两类可对比的文本类型。

之后就是最让人挠破头皮的 linguistic features 对比，包括文本长度、可读性、词汇难度、句法结构难度等，以往这些特征的不一致也是审稿人们攻击的重点。不过，今年好在有ChatGPT和Claude老师在，在语言特征计算这一步骤不必借助以往的网站上传计算，而是直接写好本地的 Python 脚本，快速又稳定地输出指标特征。这是今年实验设计初期最大的收获，之后的实验也都可以参考这个流程规范。

到这一步，第二版本的实验文本已经筛选完成（11月6日），可以进行初步的实验任务测试。

### 二、实验任务流程测试（翻译界面+眼动任务界面）


文本就像是最终要端上桌的菜，但是这道菜要经过什么程序处理、怎么做，还要根据菜的特征来设定。

所以，针对这次的游戏文本，模拟出的翻译场景必然是职业的游戏翻译流程。和上次字幕翻译有自己的职业字幕翻译软件不同，按照目前的行业经验，使用Trados等CAT工具还是这种大型翻译项目管理常见的做法。所以，首先翻译界面确定为一个CAT工具。其次，眼动仪的型号是Eyelink 1000 plus, 配套的实验任务设计软件是 Weblink 或 ExperimentBuilder。EB更偏向于心理学的短刺激物实验，而Weblink 对于网页、文档的追踪更适合翻译这种复杂认知任务。所以，使用Weblink + 一个网页版的CAT工具显然是比较合适的选择。正好经过上学期CAT课程的复习，界面简单、较好上手的网页版CAT工具中我选择了YiCAT。

经过YiCAT项目和Weblink实验任务结合的测试，基本上确定了被试的实验任务流程：

- 阅读翻译风格指南、术语表（PDF）
- 在YiCAT中完成翻译任务（Website）

<figure style="text-align: center">  
  <img src="{{chezvivian.github.io}}/images/eyelink.jpg" alt="Eyelink 眼动仪-被试机" width="400"/>  
  <figcaption><em>Eyelink 眼动仪-被试机</em></figcaption>  
</figure>  

<figure style="text-align: center">  
  <img src="{{chezvivian.github.io}}/images/tracker.jpg" alt="Eyelink 眼动仪-主试机" width="400"/>  
  <figcaption><em>Eyelink 眼动仪-主试机</em></figcaption>  
</figure>  

### 三、流程文本制作：被试流程-主试流程

确定任务流程之后，就要制作详细的标准化实验流程和文档，主要涉及的内容有：

被试方面：
- 背景信息问卷（问卷星）
- 知情同意书
- 认知负荷量表

主试方面：
- YiCAT + Weblink 实验任务创建标准流程、创建记录（避免任务创建出错）
- 总翻译任务指南 + 风格指南（给被试说明实验背景）
- YiCAT 软件培训流程（被试培训用）
- Eyelink 眼动仪设备使用流程培训（被试培训用）
- 眼动仪校准参数记录表（主试记录，用于每名被试的调参数据）
- 访谈提纲（实验后被试的访谈）
- 被试场次登记表

以上文件，有些基本是制式文件，比如和被试相关的知情同意书、认知负荷量表，符合翻译研究和以往的实验规范即可。背景信息问卷要根据研究问题定制，其他的主试流程文档也均根据实验流程设计进行定制。以上步骤虽然看起来繁琐，但是行之有效，对于控制实验的标准化流程、避免出错起到很关键的作用。

### 四、招募被试：目标对象，筛选原则

在以上实验文档、实验任务创建均初步准备完成之后，就开始招募被试。首先要确认的是研究的目标被试群体。由于这次实验的研究目的并不涉及对比职业译员和学生译员，因此从招募难度上有所降低，可以直接招募学生被试。筛选原则也就确定为英语、翻译水平，表现为MTI学历或者翻译资格证书。

招募过程中出现的问题是：一时间接收了众多的好友申请，无法及时处理被试回复。这一点在下次的实验中一定要提前预案。

这次我的解决方案是，先暂停接收申请，而是抽出半个小时时间，制作一个可参与实验场次的共享表格，确认好整个实验周期我能承担的实验场次，之后让被试们自己报名填空。这个新的尝试目前显示是有效的。和上次实验我与被试一一对接敲定时间不同，这次我把所有报名的被试拉到一个群里，在群公告中贴出共享表格的链接，让大家自行选定预约时间。同时，我也标注一些共同的注意事项。这样一来，我避免了一一回复的难题，也能在场次基本预约完毕之后，再和个别被试单独沟通问题。

## 实验过程

### A. 翻译任务、眼动任务创建和准备：

具体实验任务的创建重点在于制定标准化流程。GLOC_24实验，相对于我之前19年和21年的实验来说，每次都使用了新的眼动仪（按时间依次是Tobii X2-60, Tobii TX300, 以及这次 Eyelink 1000 plus），以及新的软件平台（依次是 Translog, WinCaps Q4, YiCAT）。每次实验任务的创建和设置都是全新的流程和逻辑，按照当时的研究目的和要测试的自变量进行定制。这次GLOC_24的研究对象是游戏翻译，所以采用了职业化的CAT工具翻译流程。同时，为了更好地利用Eyelink 配套的 Weblink 软件功能，采用了网页端的计算机辅助翻译工具YiCAT,不仅能够追踪静态的兴趣区，还能对将来感兴趣的句段进行动态定向追踪，这个功能实在是很有趣。具体任务创建的流程基本如下：

- 先创建翻译任务: YiCAT, 标准化文本、标准化项目设置。每名被试一个翻译项目，三个文本翻译任务，每个任务都生成UUID链接，用于眼动任务的刺激物。

- 再创建眼动任务：Weblink, 同样标准化项目设置：定义结束任务的快捷键：shift + Esc. 最关键的步骤：任务的顺序和命名。同样是 ParticipantID_TaskID_TextID的逻辑，三层分类有助于主试多次核对任务顺序和内容，避免出错。每个任务中，再按照A/B分组的文本刺激物进行对应上传，确保创建了正确的任务内容。

### B. 被试文档管理：电子版问卷、纸质问卷、译文、访谈录音、眼动数据的分类备份

被试文档管理是从AVT_21实验中开始养成的习惯。我会把每天收集到的被试数据，包括最初的知情同意书、背景信息问卷、访谈录音、译文等文本材料扫描为电子版存档，而眼动数据也会尽快成组、成批地保存。


### C. 工具：文件柜（纸质文档分类）、文件盒（归档）、录音笔、标签机

今年尝试的新做法是使用分层的文件柜，把所有纸质文件归档。讯飞录音笔可以使用讯飞的语音转录API，免费转录访谈内容，又省去了将来一点数据处理的工作，提高效率。标签机也很好用。

<figure style="text-align: center">  
  <img src="{{chezvivian.github.io}}/images/文件柜.jpg" alt="文件柜" width="300"/>  
  <figcaption><em>文件柜</em></figcaption>  
</figure>  

### D. 被试的状况：

第一周数据收集过程，已经出现了多种特殊情况。比如被试的睫毛很长、有刘海、做过近视矫正手术等，都有可能会影响数据收集的效果。

对应的方案是：购买睫毛夹、刘海贴、皮筋等。近视矫正手术也要看角膜的影像是否受到影响，如果没有明显问题，也可先收集起来，再看数据是否可用。

### E. 眼动设备：

- Pupil-CR 瞳孔-角膜追踪技术方法。两个阈值：pupil > 75 （否则眼睛需要更多照明光源，可调整 illuminator 功率至更高）, CR < 255

- Illuminator: 照明器功率，分 50%, 75%, 100% 三档。光线较暗时（阴天自然光）50% 的数据收集效果较好；光线明亮或被试佩戴眼镜（镜片会反射一部分红外光），这时增加照明器功率到75%，能够补偿图像对比度过低的情况。

### F. 被试培训的动态调整：

- YiCAT 软件中对术语、词汇的呈现，不能体现动词变位，需提前提醒被试记忆词汇

- 实验快捷键：shift + esc

### G. 时间管理

- 2024年11月25日-12月31日预计完成共38场，每场实验约2h。今年实验时间安排的难度在于，每周有既定的课程，更重要的是每天下午16:00之前必须结束所有实验，因为要赶在5点前接孩子幼儿园放学。时间非常受限，所幸每周最多能收集8名被试的数据，已经超出我的预期。

  - 实验场次和日常上课交叉：
  - 周一上午下午各一场（晚上6:30 商英一上课）
  - 周二上午一场（下午1:30 CAT上课）
  - 周三上午一场（早上8:00 商英一上课，下午1:30 CAT上课）
  - 周四上午下午各一场
  - 周五上午下午各一场
  
- 被试的积极参与：另一方面很庆幸的是，这次实验在秋季学期即将结束时开始，在校学生较多,学生参与积极度也很高，给了我很大的鼓舞。和上次2021年博士期间，恰逢疫情、恰逢暑假相比，被试响应的积极性提高很多。这次招募通知发布的当晚，几乎所有场次已经预约完毕，实在是很大的进步。

  
**先总结到这里。接下来边进行实验，边继续记录。（2024-11-29）**

---

## 2024-12-13 更新

在前两周的实验中发现了一些问题，主要是 Eyelink 硬件和软件的使用经验增加，并且开始尝试导出数据、进行初步处理。目前发现和解决的问题有：

### Weblink 相关

- camera setup 中默认的 force manual accept 为 No, 即默认不需要手工校准。但是 camera setup 的任务中本身就包括 calibration 和 validation. 在实际实验过程中，如果 calibrate 之后再手动 validate (手工更准一些)，在EDF中会生成validation的报告，增强数据的信度。所以，保持 force manual accept 为 No即可，但是记得校准之后再核准就会更有利于后期实验处理的数据检查和筛选。

### Eyelink 1000 plus 主试机操作

- 任务的过程中calibration之后，正式进入任务的操作按照指南应该是按键盘的O键（Output/Record）。但是，我在最近的实验中都是点击了主试机的Exit camera setup, 之后进入眼动Trial 的记录。经过和Eyelink的宋昌霖工程师沟通，已经确认我的这种操作和OO键盘操作的数据记录轨迹完全一样，生成的数据也完全一样，所以不用担心之前数据受到污染。

### Dataviewer 相关

- EDF导入处理流程：导入同一被试多个EDF（multiple data, 可选定一个母文件夹），筛选出研究关注的trial (GLOC_24中是网页内容) ，先划定兴趣期(Interest Period, IP)，再绘制或导入兴趣区(Interest Area, IA)

- 划定兴趣期的做法：这次创新的做法是，由于网页跳转的时间不一，所以每个trial 需要手工界定IP开始的点。具体做法是，在视频播放模式，选定关键帧，鼠标右键添加 New message，添加名称"start". 之后edit IP，增加一个新的IP，设置开始的节点是 EDF文件中的 message, 具体内容是 "start", 结束的节点就选为weblink中设置的任务结束快捷键即可。

- 绘制兴趣区的做法：针对本次实验任务，在任意一个任务中绘制ST, TT, Term 三个兴趣区。之后保存为 IA template, 再在每个trial分析时导入到IA template, 设为 default即可。

- 导出IA report的做法：完成以上IP, IA设置，即可在Analysis标签下导出IA report, 选定要导出的variable (variable 也可以通过某次数据导出的设置保存为template, 在其他任务导出时上传统一使用)，之后即可导出为 xls 或 txt 文件。

---

## 2024-12-17 更新

### 眼动校准 

最近检查数据，发现零星有被试的数据出现漂移的现象，也就是眼动注视点计算的位置比实际注视的位置（通过录屏判断）要高或低一两行，通常是低一两行。结合今天被试的情况，有了新的发现。

今天的被试在眼动校准时就出现瞳孔识别容易丢失、以及角膜反射区大片着色的情况。因为听被试说参加过世荣去年的实验，所以基本判断被试的基本条件是符合眼动实验要求的。接下来就是debug具体情况。首先让被试用睫毛夹把睫毛夹弯一些，避免干扰瞳孔识别，这样确实起到一些作用。睫毛夹在昨天的被试那里也显示很有用，能立刻排出一些深色着色区的干扰。第二个做法是观察大片反光的来源，从主试机上看到被试的面部不是正对着眼动仪，而是侧对着，于是想到也许跟被试的低头、抬头情况有关。果然，观察头托的位置和被试的坐姿，发现被试坐的位置靠后，所以是头向前伸的姿势，导致视线不自觉地向下，这样镜片对眼动仪来说也呈现了一定的角度，因而形成了大片的反光。

判断完这些，总结出几点眼动校准的操作指南：

A. 调整设备时，除了测量距离、高度之外，也要管理被试的坐姿和抬头情况。

<u>最佳实践：被试靠着椅背坐直，头放在头托中，不低头不抬头，可以平视屏幕。</u>

B. 睫毛较长或下垂的被试，要使用睫毛夹将睫毛夹得卷翘，不干扰对瞳孔位置的捕捉。

<u>最佳实践：使用睫毛夹。</u>

---

## 2024-12-20 更新

### 中后程：略微倦怠 + 身体抱恙

实验已经进展四周，因为上周孩子生病住院，临时取消几个场次。为了不影响数据量，几名被试又加到这周来，所以本周总共做了11名被试，全速前进。结果，到了周四周五，我也快撑不住了。做访谈的时候，都嗓音嘶哑、忍不住咳嗽。大概率是免疫力降低，被孩子的支原体传染了。

今早在一楼校医院采了指尖血，就上来迎接第一名被试。之后被试进入状态，我再下去取单子拿药。在外卖平台上买了阿奇，送到西门的外卖柜，也离得非常近，5分钟就打个来回。好在知行楼太全面了，实验室、教室、校医院融为一体，对我来说真是all-in-one。

另外就是实验的倦怠感稍稍出来一点。进展到3/4的数据量，身心都有些疲乏。有时候给被试介绍着实验背景和任务要求，脑子中会闪过自己几天前这么说话的样子，感觉像是进行重复的表演。每到晚上最后一名被试，带着做访谈盯着屏幕的时候，飞蚊症就会更加厉害，需要甩甩头才能看清屏幕上的字。

坚持，还有最后一周多，最后一组的被试。目前收集的数据中，已经发现某些试次存在一些问题，比如被试始终校准不通过、漂移情况严重等。但是按照计划收集完所有数据，也已经留了误差的余量。现在能做的，就是走好最后一公里，尽力采集完整初始数据。

### 眼动准备：带镜子

这两天的新发现是，当被试需要调整睫毛、眼睛状态时，还需要带一个镜子备用。用手机不太方便，也不准确。兴许我寒假该进修一下给人化妆，下次再帮被试夹睫毛的时候就不会畏手畏脚了。

<u>最佳实践：带镜子。</u>

### 眼动校准设置：illuminator

最近的试次基本上都是上午9:30 - 11:30, 下午 1:30 - 3:30，以及少数的 下午3:30 - 5:30。比较明显的发现是：上午的眼动仪 illuminator 照明设置为 75% 基本都可以达到不错的效果，Pupil 和 CR的值处于合理的区间。但是下午，随着外界光线变暗（虽然实验室都为关闭白色窗帘的状态，但是环境光线确实变弱），illuminator 会需要设定为 100% 才能达到一个比较好的 pupil 值，否则可能会出现pupil 值 75左右或者低于75的情况。这一点还表现在同一名被试，随着三个任务的进行，前两个任务可能设定75%即可，但是最后一个任务需要设定为100%。

<u>最佳实践：illuminator值可随着光线情况机动调整：通常75%，光线弱时使用100%。</u>

### 给予灵感的被试

今天已经更新很多了，刚才做完最后一个访谈，还是忍不住来记录一下。今天有很大的惊喜！

虽然眼动数据上可能不太稳定，上午还受到一些抖动的影响，但是下午的两名被试实在让人惊喜。这两位一个是昨天刚敲定的补录场次的同学，另一个是从上周推迟改到今天的。好庆幸没有错过她们。

两位都是有游戏经验和自己思考的同学。在有限的游戏背景资料情况下，能够推断出非常丰富的上下文和对角色的理解，以及更深一步对玩家体验的追求和塑造。非常让人激动！让我坚定了做这个主题研究的决心。游戏本地化能做的还有很多，而对于游戏的理解和激情是最难得的品质。（**标记一下2024-12-20的研究感悟。**）

## 2024-12-24 更新

最后一组进行时。今天身体有些疲惫，早上起床抱娃都有点吃力，嗓子也没有好，讲任务说明时还是一直沙哑。