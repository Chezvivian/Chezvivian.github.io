---
title: '2024-11-29 GLOC_24 实验记录'
tags:
  - thoughts
---

GLOC_24 游戏翻译眼动实验目前正在进行时，趁体验和记忆最新鲜的时候来记录一下实验前期和过程中的一些经验和感想，以给未来的实验提供一些基准，也供同事或者感兴趣的同学们进行参考。


## 实验设计

### 一、文本筛选、测试（基础和关键）

自变量的选取和文本筛选是翻译认知过程实验的一个最基础、最核心的问题，很大程度上决定了研究的价值和最终数据是否能呈现显著差异。这是重中之重，也是从实验伊始占据我最多时间的问题。今年4月份我开始准备做实验，到7月份确定基本的设计框架，通过了学院的伦理审查，也申请到了眼动实验室的使用权限。但是暑假期间，却一直卡在文本筛选这一关，一方面是全职带娃，没有任何时间可以肉身到学校；另一方面主要是研究兴趣有一点转变，在之前文章里[2024-11-03 一年总结](https://chezvivian.github.io//one-year-summary/)里也提到。所以，在经过一些调整和思考之后，GLOC_24的实验代码正式在9月30日敲定。之后的文本筛选、测试很快在一个月内就完成了（10月25日）。

文本筛选工作也是最痛苦的 dirty work. 这次游戏翻译实验，先选定游戏文本作为大的范畴，然后根据不同游戏平台、类型、文本多样性筛选出最感兴趣、最适合的单个游戏主体。下一步获取游戏全部的文本、视频 walkthrough 资料，这里包括 Game wiki 上的资料搜集、Youtube上的视频抓取，还有游戏脚本的梳理。再从这款游戏的各类文本类型中挑选出有代表性的两类可对比的文本类型。

之后就是最让人挠破头皮的 linguistic features 对比，包括文本长度、可读性、词汇难度、句法结构难度等，以往这些特征的不一致也是审稿人们攻击的重点。不过，今年好在有ChatGPT和Claude老师在，在语言特征计算这一步骤不必借助以往的网站上传计算，而是直接写好本地的 Python 脚本，快速又稳定地输出指标特征。这是今年实验设计初期最大的收获，之后的实验也都可以参考这个流程规范。

到这一步，第二版本的实验文本已经筛选完成（11月6日），可以进行初步的实验任务测试。

### 二、实验任务流程测试（翻译界面+眼动任务界面）


文本就像是最终要端上桌的菜，但是这道菜要经过什么程序处理、怎么做，还要根据菜的特征来设定。

所以，针对这次的游戏文本，模拟出的翻译场景必然是职业的游戏翻译流程。和上次字幕翻译有自己的职业字幕翻译软件不同，按照目前的行业经验，使用Trados等CAT工具还是这种大型翻译项目管理常见的做法。所以，首先翻译界面确定为一个CAT工具。其次，眼动仪的型号是Eyelink 1000 plus, 配套的实验任务设计软件是 Weblink 或 ExperimentBuilder。EB更偏向于心理学的短刺激物实验，而Weblink 对于网页、文档的追踪更适合翻译这种复杂认知任务。所以，使用Weblink + 一个网页版的CAT工具显然是比较合适的选择。正好经过上学期CAT课程的复习，界面简单、较好上手的网页版CAT工具中我选择了YiCAT。

经过YiCAT项目和Weblink实验任务结合的测试，基本上确定了被试的实验任务流程：

- 阅读翻译风格指南、术语表（PDF）
- 在YiCAT中完成翻译任务（Website）

<figure style="text-align: center">  
  <img src="{{chezvivian.github.io}}/images/eyelink.jpg" alt="Eyelink 眼动仪-被试机" width="400"/>  
  <figcaption><em>Eyelink 眼动仪-被试机</em></figcaption>  
</figure>  

<figure style="text-align: center">  
  <img src="{{chezvivian.github.io}}/images/tracker.jpg" alt="Eyelink 眼动仪-主试机" width="400"/>  
  <figcaption><em>Eyelink 眼动仪-主试机</em></figcaption>  
</figure>  

### 三、流程文本制作：被试流程-主试流程

确定任务流程之后，就要制作详细的标准化实验流程和文档，主要涉及的内容有：

被试方面：
- 背景信息问卷（问卷星）
- 知情同意书
- 认知负荷量表

主试方面：
- YiCAT + Weblink 实验任务创建标准流程、创建记录（避免任务创建出错）
- 总翻译任务指南 + 风格指南（给被试说明实验背景）
- YiCAT 软件培训流程（被试培训用）
- Eyelink 眼动仪设备使用流程培训（被试培训用）
- 眼动仪校准参数记录表（主试记录，用于每名被试的调参数据）
- 访谈提纲（实验后被试的访谈）
- 被试场次登记表

以上文件，有些基本是制式文件，比如和被试相关的知情同意书、认知负荷量表，符合翻译研究和以往的实验规范即可。背景信息问卷要根据研究问题定制，其他的主试流程文档也均根据实验流程设计进行定制。以上步骤虽然看起来繁琐，但是行之有效，对于控制实验的标准化流程、避免出错起到很关键的作用。

### 四、招募被试：目标对象，筛选原则

在以上实验文档、实验任务创建均初步准备完成之后，就开始招募被试。首先要确认的是研究的目标被试群体。由于这次实验的研究目的并不涉及对比职业译员和学生译员，因此从招募难度上有所降低，可以直接招募学生被试。筛选原则也就确定为英语、翻译水平，表现为MTI学历或者翻译资格证书。

招募过程中出现的问题是：一时间接收了众多的好友申请，无法及时处理被试回复。这一点在下次的实验中一定要提前预案。

这次我的解决方案是，先暂停接收申请，而是抽出半个小时时间，制作一个可参与实验场次的共享表格，确认好整个实验周期我能承担的实验场次，之后让被试们自己报名填空。这个新的尝试目前显示是有效的。和上次实验我与被试一一对接敲定时间不同，这次我把所有报名的被试拉到一个群里，在群公告中贴出共享表格的链接，让大家自行选定预约时间。同时，我也标注一些共同的注意事项。这样一来，我避免了一一回复的难题，也能在场次基本预约完毕之后，再和个别被试单独沟通问题。

## 实验过程

### A. 翻译任务、眼动任务创建和准备：

具体实验任务的创建重点在于制定标准化流程。GLOC_24实验，相对于我之前19年和21年的实验来说，每次都使用了新的眼动仪（按时间依次是Tobii X2-60, Tobii TX300, 以及这次 Eyelink 1000 plus），以及新的软件平台（依次是 Translog, WinCaps Q4, YiCAT）。每次实验任务的创建和设置都是全新的流程和逻辑，按照当时的研究目的和要测试的自变量进行定制。这次GLOC_24的研究对象是游戏翻译，所以采用了职业化的CAT工具翻译流程。同时，为了更好地利用Eyelink 配套的 Weblink 软件功能，采用了网页端的计算机辅助翻译工具YiCAT,不仅能够追踪静态的兴趣区，还能对将来感兴趣的句段进行动态定向追踪，这个功能实在是很有趣。具体任务创建的流程基本如下：

- 先创建翻译任务: YiCAT, 标准化文本、标准化项目设置。每名被试一个翻译项目，三个文本翻译任务，每个任务都生成UUID链接，用于眼动任务的刺激物。

- 再创建眼动任务：Weblink, 同样标准化项目设置：定义结束任务的快捷键：shift + Esc. 最关键的步骤：任务的顺序和命名。同样是 ParticipantID_TaskID_TextID的逻辑，三层分类有助于主试多次核对任务顺序和内容，避免出错。每个任务中，再按照A/B分组的文本刺激物进行对应上传，确保创建了正确的任务内容。

### B. 被试文档管理：电子版问卷、纸质问卷、译文、访谈录音、眼动数据的分类备份

被试文档管理是从AVT_21实验中开始养成的习惯。我会把每天收集到的被试数据，包括最初的知情同意书、背景信息问卷、访谈录音、译文等文本材料扫描为电子版存档，而眼动数据也会尽快成组、成批地保存。


### C. 工具：文件柜（纸质文档分类）、文件盒（归档）、录音笔、标签机

今年尝试的新做法是使用分层的文件柜，把所有纸质文件归档。讯飞录音笔可以使用讯飞的语音转录API，免费转录访谈内容，又省去了将来一点数据处理的工作，提高效率。标签机也很好用。

<figure style="text-align: center">  
  <img src="{{chezvivian.github.io}}/images/文件柜.jpg" alt="文件柜" width="300"/>  
  <figcaption><em>文件柜</em></figcaption>  
</figure>  

### D. 被试的状况：

第一周数据收集过程，已经出现了多种特殊情况。比如被试的睫毛很长、有刘海、做过近视矫正手术等，都有可能会影响数据收集的效果。

对应的方案是：购买睫毛夹、刘海贴、皮筋等。近视矫正手术也要看角膜的影像是否受到影响，如果没有明显问题，也可先收集起来，再看数据是否可用。

### E. 眼动设备：

- Pupil-CR 瞳孔-角膜追踪技术方法。两个阈值：pupil > 75 （否则眼睛需要更多照明光源，可调整 illuminator 功率至更高）, CR < 255

- Illuminator: 照明器功率，分 50%, 75%, 100% 三档。光线较暗时（阴天自然光）50% 的数据收集效果较好；光线明亮或被试佩戴眼镜（镜片会反射一部分红外光），这时增加照明器功率到75%，能够补偿图像对比度过低的情况。

### F. 被试培训的动态调整：

- YiCAT 软件中对术语、词汇的呈现，不能体现动词变位，需提前提醒被试记忆词汇

- 实验快捷键：shift + esc

### G. 时间管理

- 2024年11月25日-12月31日预计完成共38场，每场实验约2h。今年实验时间安排的难度在于，每周有既定的课程，更重要的是每天下午16:00之前必须结束所有实验，因为要赶在5点前接孩子幼儿园放学。时间非常受限，所幸每周最多能收集8名被试的数据，已经超出我的预期。

  - 实验场次和日常上课交叉：
  - 周一上午下午各一场（晚上6:30 商英一上课）
  - 周二上午一场（下午1:30 CAT上课）
  - 周三上午一场（早上8:00 商英一上课，下午1:30 CAT上课）
  - 周四上午下午各一场
  - 周五上午下午各一场
  
- 被试的积极参与：另一方面很庆幸的是，这次实验在秋季学期即将结束时开始，在校学生较多,学生参与积极度也很高，给了我很大的鼓舞。和上次2021年博士期间，恰逢疫情、恰逢暑假相比，被试响应的积极性提高很多。这次招募通知发布的当晚，几乎所有场次已经预约完毕，实在是很大的进步。

  
**先总结到这里。接下来边进行实验，边继续记录。（2024-11-29）**

---

## 2024-12-13 更新

在前两周的实验中发现了一些问题，主要是 Eyelink 硬件和软件的使用经验增加，并且开始尝试导出数据、进行初步处理。目前发现和解决的问题有：

### Weblink 相关

- camera setup 中默认的 force manual accept 为 No, 即默认不需要手工校准。但是 camera setup 的任务中本身就包括 calibration 和 validation. 在实际实验过程中，如果 calibrate 之后再手动 validate (手工更准一些)，在EDF中会生成validation的报告，增强数据的信度。所以，保持 force manual accept 为 No即可，但是记得校准之后再核准就会更有利于后期实验处理的数据检查和筛选。

### Eyelink 1000 plus 主试机操作

- 任务的过程中calibration之后，正式进入任务的操作按照指南应该是按键盘的O键（Output/Record）。但是，我在最近的实验中都是点击了主试机的Exit camera setup, 之后进入眼动Trial 的记录。经过和Eyelink的宋昌霖工程师沟通，已经确认我的这种操作和OO键盘操作的数据记录轨迹完全一样，生成的数据也完全一样，所以不用担心之前数据受到污染。

### Dataviewer 相关

- EDF导入处理流程：导入同一被试多个EDF（multiple data, 可选定一个母文件夹），筛选出研究关注的trial (GLOC_24中是网页内容) ，先划定兴趣期(Interest Period, IP)，再绘制或导入兴趣区(Interest Area, IA)

- 划定兴趣期的做法：这次创新的做法是，由于网页跳转的时间不一，所以每个trial 需要手工界定IP开始的点。具体做法是，在视频播放模式，选定关键帧，鼠标右键添加 New message，添加名称"start". 之后edit IP，增加一个新的IP，设置开始的节点是 EDF文件中的 message, 具体内容是 "start", 结束的节点就选为weblink中设置的任务结束快捷键即可。

- 绘制兴趣区的做法：针对本次实验任务，在任意一个任务中绘制ST, TT, Term 三个兴趣区。之后保存为 IA template, 再在每个trial分析时导入到IA template, 设为 default即可。

- 导出IA report的做法：完成以上IP, IA设置，即可在Analysis标签下导出IA report, 选定要导出的variable (variable 也可以通过某次数据导出的设置保存为template, 在其他任务导出时上传统一使用)，之后即可导出为 xls 或 txt 文件。